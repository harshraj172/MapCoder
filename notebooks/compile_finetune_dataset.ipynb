{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(file_path):\n",
    "    \"\"\"\n",
    "    Generator function to read a JSONL file.\n",
    "    \n",
    "    :param file_path: Path to the JSONL file\n",
    "    :return: A dictionary representing each JSON object\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "        \n",
    "def write_jsonl(data, file_path):\n",
    "    \"\"\"\n",
    "    Function to write a list of dictionaries to a JSONL file.\n",
    "    \n",
    "    :param data: List of dictionaries to write\n",
    "    :param file_path: Path to the JSONL file where the data will be written\n",
    "    \"\"\"\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        for item in data:\n",
    "            json_line = json.dumps(item)\n",
    "            file.write(json_line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 13.0k/13.0k [00:00<00:00, 8.65MB/s]\n",
      "Downloading metadata: 100%|██████████| 4.52k/4.52k [00:00<00:00, 10.4MB/s]\n",
      "Downloading data: 100%|██████████| 39/39 [08:13<00:00, 12.64s/files]\n",
      "Downloading data: 100%|██████████| 63.1M/63.1M [00:05<00:00, 11.5MB/s]\n",
      "Downloading data: 100%|██████████| 51.8M/51.8M [00:05<00:00, 10.3MB/s]\n",
      "Generating train split: 100%|██████████| 13328/13328 [01:24<00:00, 157.08 examples/s]\n",
      "Generating test split: 100%|██████████| 165/165 [00:00<00:00, 220.58 examples/s]\n",
      "Generating valid split: 100%|██████████| 117/117 [00:00<00:00, 140.69 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "data = load_dataset(\"deepmind/code_contests\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = []\n",
    "for oo in data:\n",
    "    sample_data.append(\n",
    "        {\n",
    "            \"name\": oo[\"name\"],\n",
    "            \"description\": oo[\"description\"],\n",
    "            \"tags\": oo[\"cf_tags\"],\n",
    "            \"difficulty\": oo[\"difficulty\"],\n",
    "            \"id\": oo[\"cf_contest_id\"],\n",
    "            \"sample_io\": oo[\"public_tests\"],\n",
    "            \"test_list\": oo[\"private_tests\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "random.shuffle(sample_data)\n",
    "\n",
    "write_jsonl(sample_data[:25], \"./data/CodeContest/Train-sampled.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "1. Run GPT4 across all the 5 prompting strategy on the 25 sampled from the training data saved in the above cell (`./data/CodeContest/Train-sampled.jsonl`). Use language as **Rust**\n",
    "2. Mix the data randomly which creates 125 sampled.\n",
    "3. Convert the data into OpenAI acceptable message format.\n",
    "4. Finetune *gpt-3.5-turbo-0125*. \n",
    "\n",
    "**Note:** This strategy of finetuning is motivated from the [FireAct](https://arxiv.org/abs/2310.05915) work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dummy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
